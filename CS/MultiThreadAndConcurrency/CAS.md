# CAS연산

- 대부분 복잡한 동시성 라이브러리들이 CAS연산을 사용한다
  - Java의 AtomicInteger은 CAS연산을 사용한다

## 락 기반 방식의 문제점

- 락은 특정 자원을 보호하기 위해 스레드가 해당 자원에 대한 접근하는 것을 제한한다
- 락이 걸려있는 동안 다른 스레드들은 해당 자원에 접근할 수 없고, 락이 해제될 때까지 기다려야 한다
- 또한 락 기반 접근에서는 락을 획득하고 해제하는데 까지 시간이 필요하다
- 락을 사용하는 방식은 직관적이지만 무거운 방식이다(10000번의 연산이 이다면, 10000번 모두 락 확인-락 반납을 수행해야 한다)

## CAS

- 락의 문제를 해결하기위해 락을 걸지 않고 원자적인 연산을 수행할 수 있는 방법이 있다
- CAS(Compare and swap, compare and set)연산이라고 한다
- 락을 사용하지 않기에 lock-free 기법이라고 한다
- 락을 완전히 대체하지는 않고, 작은 단위의 일부 영역에 적용할 수 있다
- 기본은 락을 사용하고, 특별한 경우에 CAS를 적용할 수 있다고 생각하면 된다
- CAS연산의 특징은 원자적이라는 것이다
  - 소프트웨어가 지원하는 기능이 아닌 하드웨어가 지원하는 기능이다
  - CPU는 다음 두 과정을 묶어서 하나의 원자적인 명령으로 만들어버린다. 따라서 중간에 다른 스레드가 개입할 수 없다
    - x001의 값을 확인
    - 읽은 값이 0이면 1로 변경한다
- java의 예제

```java
        AtomicInteger atomicInteger = new AtomicInteger(0);
        System.out.println("start value = " + atomicInteger.get());

        // 비교하고, 같으면 연산
        boolean result1 = atomicInteger.compareAndSet(0, 1); // 1
        // 1. if 기대하는 값이 0 이면, 2. 값을 1로 변경해 -> 원자적이 아닌데?
        // 위 연산은 CPU가 원자적인 연산으로 만들어준다
        // JVM이 연산을 하나로 묶어 CPU에 전달한다 CMPXCHG [memory], register
        // 즉 하드웨어가 연산을 지원한다
        System.out.println("result1 = " + result1 + ", value = " + atomicInteger.get());

        boolean result2 = atomicInteger.compareAndSet(0, 1); // false, 값을 바꾸지 않는다
        System.out.println("result2 = " + result2 + ", value = " + atomicInteger.get());
```

- java를 이용한 psedo code

```java
   private static int incrementAndGet(AtomicInteger atomicInteger) {
        int getValue;
        boolean result;
        do {
            getValue = atomicInteger.get(); // thread1: 0
            log("getValue: " + getValue);
            // value++가 아닌 값을 바꾸는 것이다 0과 1
            // 다른 스레드가 값을 바꿔버리면 실패하는게 CAS 연산이다
            result = atomicInteger.compareAndSet(getValue, getValue + 1);
            log("result: " + result);
        } while (!result);
        return getValue + 1;
    }
```

- CAS연산의 핵심은 내가 바꾸기 전까지 값을 유지시키는 것이다
- CAS연산의 과정
  1. 현재 변수의 값을 읽어온다
  2. 변수의 값을 1 증가시킬때, 원래 값이 같은지 확인한다(CAS 연산 사용)
  3. 동일하다면 증가된 값을 변수에 저장하고 종료한다
  4. 동일하지 않다면 다른 스레드가 값을 중간에 변경한 것이므로, 다시 처음으로 돌아가 위 과정을 반복한다
- 두 스레드가 동시에 실행되면서 문제가 발생하는 상황을 스레드가 충돌했다고 표현한다
  - 이 과정에서 충돌이 발생할 때마다 반복해서 다시 시도하므로, 결과적으로 락 없이 데이터를 안전하게 변경할 수 있다
  - CAS를 사용하는 방식은 충돌이 드물게 발생하는 환경에서는 락을 사용하지 않으므로 높은 성능을 발휘할 수 있다
  - 이는 락을 사용하는 방식과 비교했을 때, 스레드가 락을 획득하려고 대기하지 않기 때문에 대기시간과 오버헤드가 줄어드는 장점이 있다
  - 그러나 충돌이 빈벅한 환경에서는 성능이 문제가 될 수 있다
  - 여러 스레드가 자주 동시에 동일한 변수의 값을 변경하려고 시도할 때, CAS는 자주 실패하고 재시도 하므로 성능저하가 발생할 수 있다
  - 이런 상황에서는 반복문을 계속 돌기 때문에 CPU자원을 많이 소모하게 된다

## CAS와 Lock 방식의 비교

- 락 방식
  - 비관적(pessimistic) 접근법
    - 최악의 상황을 가정
  - 데이터에 접근하기 전에 항상 락을 획득
  - 입구를 한개만 만든다
  - 다른 스레드의 접근을 막음
  - '다른 스레드가 방해할 것이다'라고 가정
- CAS방식
  - 낙관적(optimistic) 접근법
    - 락을 사용하지 않고 데이터에 바로 접근
  - 충돌이 발생하면 그때 재시도
  - '대부분의 경우 충돌이 없을 것이다'라고 가정

### CAS 장점

1. 낙관적 동기화: 락을 걸지 않고도 값을 안전하게 업데이트 할 수 있다. CAS는 충돌이 자주 발생하지 않을 것이라고 가정한다. 이는 충돌이 적은환경에서 높은 성능을 발휘한다
2. 락 프리(lock-free): CAS는 락을 사용하지 않기 때문에, 락을 획득하기 위해 대기하는 시간이 없다. 따라서 스레드가 블로킹 되지 않으며, 병렬 처리가 더 효율적일 수 있다.

### CAS 단점

1. 충돌이 빈번한 경우: 여러 스레드가 동시에 동일한 변수에 접근해 업데이트를 시도할 때 충돌이 발생할 수 있다. 충돌이 발생하면 CAS는 루프를 돌며 재시도하며, 이에 따라 CPU자원을 계쏙 소모할 수 있다. 반복적인 재시도로 인한 오버헤드의 발생 가능성이 있다
2. 스핀락과 유사한 오버헤드: CAS는 충돌 시 반복적으로 재시도를 하므로, 이 과정이 계속 반복되면 스핀락과 유사한 성능저하가 발생할 수 있다. 특히 충돌 빈도가 높을 수록 이런 현상이 두드러진다

### 동기화 락의 장점

1. 충돌 관리: 락을 사용하면 하나의 스레드만 리소스에 접근할 수 있으므로, 충돌이 발생하지 않는다. 여러 스레드가 경쟁할 경우에도 안정적으로 동작한다
2. 안정성: 복잡한 상황에서도 락은 일관성 있는 동작을 보장한다
3. 스레드 대기: 락을 대기하는 스레드는 CPU를 거의 사용하지 않는다

### 동기화 락의 단점

1. 락 획득 대기 시간: 스레드가 락을 획득하기 위해 대기하므로, 대기 시간이 길어질 수 있다
2. 컨텍스트 스위칭 오버헤드: 락을 사용하면, 락 획득을 위해 대기하는 시점과 또 락을 획득하는 시점에 스레드의 상태가 변경된다. 이 때 컨텍스트 스위칭이 발생할 수 있으며, 이로 인한 오버헤드가 증가할 수 있다
   - 동기화 락의 가장 큰 치명적인 단점이다

### CAS 사용하는 곳

- 충돌이 많이 없는 경우 CAS연산이 빠른 것을 확인할 수 있다
- 그럼 충돌이 많이 발생하지 않는 연산은 무엇인가? 언제 좋을까?
  - 간단한 CPU연산의 너무 빨리 처리되어 충돌이 자주 발생하지는 않지만, CAS를 사용하는 것이 효과적이다
    - 충돌이 발생하기도 전에 이미 연산을 완료하는 경우가 더 많다

### Lock을 사용하는 곳

- Lock의 경우 복잡한 비즈니스 로직이 있는 곳에서 CAS를 사용하면 많은 충돌이 일어나 비효율적이 되어, Lock을 사용하는 것이 더 효과적이다
